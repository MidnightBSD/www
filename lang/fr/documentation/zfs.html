<!DOCTYPE html>
<html lang="fr-FR">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>MidnightBSD ZFS Documentation</title>
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" type="text/css" href="../../css/essence.css">
</head>
<body>
<div id="globe">
    <div id="header"><h1 title="MidnightBSD Home"><a href="../" title="MidnightBSD Home">MidnightBSD: Le Système BSD pour Tous</a></h1></div>
    <!--#include virtual="/menu.html"-->
    <div class="clear"></div>
    <div id="text">
        <h2><img src="../../images/oxygen/doc32.png" alt=""/> Documentation ZFS</h2>
        <div id="toc">
            <h3>Contenu</h3>
            <ul>
                <li><a href="#s1b">Introduction</a></li>
                <li><a href="#s1c">Préparation</a></li>
                <li><a href="#s1d">Examples</a></li>
                <li><a href="#s1e">Récupération</a></li>
                <li><a href="#s1f">Snapshots</a></li>
                <li><a href="#s1g">Envoyer/Recevoir</a></li>
                <li><a href="#s1h">Disques durs de formats avancés (4k sector)</a></li>
                <li><a href="index.html"><strong>Documentation</strong></a></li>
            </ul>
        </div>
        <h3 id="s1a">ZFS</h3>
        <h4 id="s1b">Introduction</h4>
        <p>ZFS est un système de fichiers développé pour Oracle Solaris. Il a été publié en open source par OpenSolaris sous CDDL.
            FreeBSD a créé un port du système de fichier pour FreeBSD 7.0-CURRENT.
            Cela a été importé dans MidnightBSD avec la version 0.3-CURRENT.</p>

        <p>ZFS est considéré comme une alternative au système de fichiers UFS2 dans MidnightBSD.
            Il possède des fonctionnalités de RAID indépendantes qui ne sont pas liées aux classes GEOM.
            Il n'utilise pas le cache VFS et a quelques problèmes avec NFS.
            Les avantages incluent la prise en charge de très grands systèmes de fichiers et de grands pools de disques.
            Il prend en charge la vérification de l'intégrité des données de contrôle et peut réparer les données incorrectes lorsque le raid est utilisé.</p>

        <p>MidnightBSD inclut le système de fichiers ZFS et les groupes de disques (Storage Spool) dans la version 0.6.
            Il est possible d'accéder aux groupes de disques créés à partir d'autres systèmes d'exploitation de la même version ou inférieure.
            Si vous mettez à jour jusqu'à la version 6, vous ne pourrez plus lire les anciennes versions.
        </p>

        <h4 id="s1c">Préparer</h4>
        <p>ZFS peut être utilisé de deux manières. Il est possible de soit dédier des disques entier à ZFS
            (méthode recommandée); soit utiliser une partition GPT (mnbsd-zfs depuis 0.4-CURRENT)
            pour ajouter des disques au groupe.
            ZFS se révéle lorsqu'il est utilisé avec les fonctionnalités RAID.
        </p>

        <p>Si vous souhaitez utilisé le RAID, déterminez combien de disques vous voulez utilisez.
            Il est préférable de regrouper les disques de tailles identiques ensemble.
            Si possible, utilisez la même marque ainsi que le même modèle de disques quand vous utilisez les mirroring.
            Si vous avez deux disques, utilisez les en miroir. Si vous avez plus de deux disques,
            envisagez d'utilisez le raidz.
            Vous pouvez ajouter plusieurs sets de mirroirs (2 à la fois) dans le groupe.
        </p>

        <!-- Continuer ici -->

        <p>ZFS also supports adding spare drives to the pool. They will be used automatically when a drive fails.</p>

        <p>It is strongly recommended to use ZFS only with amd64 MidnightBSD and only on systems with more
            than 1GB of RAM. It will require tuning sysctl's to get the right balance of memory usage. Particularly,
            you need to watch the ARC size as it can grow very large</p>

        <p>MidnightBSD does not support booting from ZFS at this time. It may be added in a future release. You need
            a UFS/UFS2 partition for / including /boot, but /var, /tmp, /usr and /home can be on ZFS.</p>

        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
             style="display:block; text-align:center;"
             data-ad-format="fluid"
             data-ad-layout="in-article"
             data-ad-client="ca-pub-1321195614665440"
             data-ad-slot="7690332509"></ins>
        <script>
            (adsbygoogle = window.adsbygoogle || []).push({});
        </script>

        <h4 id="s1d">Examples</h4>

        <p>In these examples, mpool and tank are used as pool names. You can pick any name for the pool, but tank is
            very
            common. After creating a pool named tank, you'll see /tank</p>

        <p>You will most likely want to add zfs_enable="YES" into /etc/rc.conf so that ZFS is loaded on system
            startup</p>

        <p>Create a mirror</p>
        <code>zpool create mpool mirror /dev/ad0 /dev/ad1</code>

        <p>Add a spare drive</p>
        <code> zpool add mpool spare /dev/ad3</code>

        <p>Check status</p>
        <code>zpool status</code>

        <p>Listing information about pools</p>
        <code>zpool list</code>
        <code>zfs list</code>

        <p>Create file systems</p>
        <code>zfs create mpool/data</code>

        <p>Use raidz instead (raid 5 like mode)</p>
        <code>zpool add tank raidz /dev/ad0 /dev/ad1 /dev/ad2</code>

        <p>Scrub data (check for errors)</p>
        <code>zpool scrub tank</code>

        <h4 id="s1e">Recovery</h4>

        <p>During a hardware upgrade such as moving to a new motherboard or controller,
            one might find their zpool damaged. Usually the cause is that the device name has
            changed. For instance, a recent upgrade moved ad6 to ad12.</p>
        <p>To fix this problem,
            several steps are required.
        <ul>
            <li><code>rm /boot/zfs/zpool.cache & shutdown -r now</code></li>
            <li>
                <code>zpool list</code>. This should not show the pool.
            </li>
            <li><code>zpool import</code>. It should show you possible pools to recover.</li>
            <li>
                Finally, try <code>zpool import <em>name of pool</em></code>.
            </li>
        </ul>

        <p>To verify it worked, run <code>zpool list</code></p>

        <h4 id="s1f">Snapshots</h4>

        <p>A ZFS snapshot, is a point in time copy or bookmark of your data. You can use
            it to compare changes made to a file system or to backup a file system. This allows
            you to get your data back after trying an upgrade, etc. It can be a handy trick
            to make copies of jails easily.
        </p>

        <p>You can create a snapshot named 1 using the following:</p>
        <code>zfs snapshot tank/test@1</code>

        <p>You can also apply a snapshot recursively to all file systems in a pool
            with the r flag</p>

        <code>zfs snapshot -r tank/home@now</code>

        <p>As more changes occur to a file system, the amount of disk space a snapshot
            takes increases. You will want to purge old snapshots to free up disk space
            when they are no longer needed.</p>

        <code>zfs destroy tank/home@now</code>

        <p>You can use the rename command to rename a snapshot, the hold command to
            prevent removal of a snapshot, and many more options. Consult the
            relevant man pages for more information.</p>

        <p>Finally, you can list snapshots</p>
        <code>zfs list -t snapshot</code>

        <p>You can also make zfs list show snapshots by default by changing this setting
            <code>zpool set listsnapshots=on tank</code></p>

        <h4 id="s1g">Using Send and Receive</h4>
        <p>You can use zfs to send a snapshot to the same or another pool with the
            zfs send and receive commands. This can be used to backup ZFS file systems
            to another location such as an external disk.</p>

        <p>To backup the snapshot named 1 from file system test:
            <code>
                zfs send tank/test@1 | zfs receive tank/testback
            </code>
        </p>

        <h4 id="s1h">Advanced format hard drives (4k sector)</h4>

        <p>Many 4k sector drives do not report their size properly in a bad attempt
            at backward compatibility. ZFS works fine with drives that report
            properly, but for the rest of them the following workaround is
            recommended.
        </p>
        <p>
            <code>
                gpart create -s gpt ada0<br>

                # create partitions<br>
                gpart add -a 1m -t mnbsd-zfs -l drive0 ada0<br>
                gpart add -a 1m -t mnbsd-zfs -l drive1 ada1<br>

                # use gnop to make 4k friendly devices <br>
                gnop create -S 4k gpt/drive0<br>
                gnop create -S 4k gpt/drive1<br>

                # make a mirror<br>
                zpool create mpool mirror /dev/gpt/drive0.nop /dev/gpt/drive1.nop<br>

                # export pool and remove virtual devices<br>
                zpool export mpool<br>
                gnop destroy gpt/drive0.nop<br>
                gnop destroy gpt/drive1.nop<br>

                # import and keep labels (via -d flag)<br>
                zpool import -d /dev/gpt mpool<br>
            </code>
        </p>

        <!--#include virtual="/disqus.html"-->
    </div>
    <!--#include virtual="/footer.html"-->
</body>
</html>
