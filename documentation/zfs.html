<!DOCTYPE html>
<html lang="en-US">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>MidnightBSD ZFS Documentation</title>
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" type="text/css" href="../css/essence.css">
</head>
<body>
<div id="globe">
    <div id="header"><h1 title="MidnightBSD Home"><a href="../" title="MidnightBSD Home">MidnightBSD: The BSD For
        Everyone</a></h1></div>
    <!--#include virtual="/menu.html"-->
    <div class="clear"></div>
    <div id="text">
        <h2><img src="../images/oxygen/doc32.png" alt=""/> ZFS Documentation</h2>
        <div id="toc">
            <h3>Contents</h3>
            <ul>
                <li><a href="#s1b">Introduction</a></li>
                <li><a href="#s1c">Preparing</a></li>
                <li><a href="#s1d">Examples</a></li>
                <li><a href="#s1e">Recovery</a></li>
                <li><a href="#s1f">Snapshots</a></li>
                <li><a href="#s1g">Send/Receive</a></li>
                <li><a href="#s1h">Advanced format hard drives (4k sector)</a></li>
                <li><a href="index.html"><strong>Documentation</strong></a></li>
            </ul>
        </div>
        <h3 id="s1a">ZFS</h3>
        <h4 id="s1b">Introduction</h4>
        <p>ZFS is a file system developed for Oracle Solaris. It was released as open source under the CDDL
            with OpenSolaris. FreeBSD created a port of the file system for FreeBSD 7.0-CURRENT. It was imported
            into MidnightBSD with 0.3-CURRENT.</p>

        <p>ZFS is considered an alternative file system to UFS2 in MidnightBSD. It has independant RAID features
            that are not tied to GEOM classes. It does not make use of the VFS cache and has some issues with
            NFS. Advantages include support for very large file systems and large pools of disks. it supports
            checksum data integrety checking and can repair bad data when raidz is used.</p>

        <p>MidnightBSD includes ZFS file system and storage pool version 6. You may access pools created
            on other operating systems at or below this version. If you upgrade to version 6, you will no
            longer be able to read them on older versions.</p>

        <h4 id="s1c">Prepairing</h4>
        <p>ZFS can be used in two ways. You may either dedicate entire disks to ZFS (recommended) or use
            GPT partitions (mnbsd-zfs in 0.4-CURRENT) to add to a pool. ZFS shines when used with RAID features.
        </p>

        <p>If you're going to use RAID, determine how many disks you want to use. It's best to group them
            in identical sizes. If possible, use the same brand and model of drives when using mirroring.
            If you have two drives, use mirror. If you have more than two drives, consider using raidz. You
            may add multiple mirror sets (2 at a time) to the pool.</p>

        <p>ZFS also supports adding spare drives to the pool. They will be used automatically when a drive fails.</p>

        <p>It is strongly recommended to use ZFS only with amd64 MidnightBSD and only on systems with more
            than 1GB of RAM. It will require tuning sysctl's to get the right balance of memory usage. Particularly,
            you need to watch the ARC size as it can grow very large</p>

        <p>MidnightBSD does not support booting from ZFS at this time. It may be added in a future release. You need
            a UFS/UFS2 partition for / including /boot, but /var, /tmp, /usr and /home can be on ZFS.</p>

        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
             style="display:block; text-align:center;"
             data-ad-format="fluid"
             data-ad-layout="in-article"
             data-ad-client="ca-pub-1321195614665440"
             data-ad-slot="7690332509"></ins>
        <script>
            (adsbygoogle = window.adsbygoogle || []).push({});
        </script>

        <h4 id="s1d">Examples</h4>

        <p>In these examples, mpool and tank are used as pool names. You can pick any name for the pool, but tank is
            very
            common. After creating a pool named tank, you'll see /tank</p>

        <p>You will most likely want to add zfs_enable="YES" into /etc/rc.conf so that ZFS is loaded on system
            startup</p>

        <p>Create a mirror</p>
        <code>zpool create mpool mirror /dev/ad0 /dev/ad1</code>

        <p>Add a spare drive</p>
        <code> zpool add mpool spare /dev/ad3</code>

        <p>Check status</p>
        <code>zpool status</code>

        <p>Listing information about pools</p>
        <code>zpool list</code>
        <code>zfs list</code>

        <p>Create file systems</p>
        <code>zfs create mpool/data</code>

        <p>Use raidz instead (raid 5 like mode)</p>
        <code>zpool add tank raidz /dev/ad0 /dev/ad1 /dev/ad2</code>

        <p>Scrub data (check for errors)</p>
        <code>zpool scrub tank</code>

        <h4 id="s1e">Recovery</h4>

        <p>During a hardware upgrade such as moving to a new motherboard or controller,
            one might find their zpool damaged. Usually the cause is that the device name has
            changed. For instance, a recent upgrade moved ad6 to ad12.</p>
        <p>To fix this problem,
            several steps are required.
        <ul>
            <li><code>rm /boot/zfs/zpool.cache & shutdown -r now</code></li>
            <li>
                <code>zpool list</code>. This should not show the pool.
            </li>
            <li><code>zpool import</code>. It should show you possible pools to recover.</li>
            <li>
                Finally, try <code>zpool import <em>name of pool</em></code>.
            </li>
        </ul>

        <p>To verify it worked, run <code>zpool list</code></p>

        <h4 id="s1f">Snapshots</h4>

        <p>A ZFS snapshot, is a point in time copy or bookmark of your data. You can use
            it to compare changes made to a file system or to backup a file system. This allows
            you to get your data back after trying an upgrade, etc. It can be a handy trick
            to make copies of jails easily.
        </p>

        <p>You can create a snapshot named 1 using the following:</p>
        <code>zfs snapshot tank/test@1</code>

        <p>You can also apply a snapshot recursively to all file systems in a pool
            with the r flag</p>

        <code>zfs snapshot -r tank/home@now</code>

        <p>As more changes occur to a file system, the amount of disk space a snapshot
            takes increases. You will want to purge old snapshots to free up disk space
            when they are no longer needed.</p>

        <code>zfs destroy tank/home@now</code>

        <p>You can use the rename command to rename a snapshot, the hold command to
            prevent removal of a snapshot, and many more options. Consult the
            relevant man pages for more information.</p>

        <p>Finally, you can list snapshots</p>
        <code>zfs list -t snapshot</code>

        <p>You can also make zfs list show snapshots by default by changing this setting
            <code>zpool set listsnapshots=on tank</code></p>

        <h4 id="s1g">Using Send and Receive</h4>
        <p>You can use zfs to send a snapshot to the same or another pool with the
            zfs send and receive commands. This can be used to backup ZFS file systems
            to another location such as an external disk.</p>

        <p>To backup the snapshot named 1 from file system test:
            <code>
                zfs send tank/test@1 | zfs receive tank/testback
            </code>
        </p>

        <h4 id="s1h">Advanced format hard drives (4k sector)</h4>

        <p>Many 4k sector drives do not report their size properly in a bad attempt
            at backward compatibility. ZFS works fine with drives that report
            properly, but for the rest of them the following workaround is
            recommended.
        </p>
        <p>
            <code>
                gpart create -s gpt ada0<br>

                # create partitions<br>
                gpart add -a 1m -t mnbsd-zfs -l drive0 ada0<br>
                gpart add -a 1m -t mnbsd-zfs -l drive1 ada1<br>

                # use gnop to make 4k friendly devices <br>
                gnop create -S 4k gpt/drive0<br>
                gnop create -S 4k gpt/drive1<br>

                # make a mirror<br>
                zpool create mpool mirror /dev/gpt/drive0.nop /dev/gpt/drive1.nop<br>

                # export pool and remove virtual devices<br>
                zpool export mpool<br>
                gnop destroy gpt/drive0.nop<br>
                gnop destroy gpt/drive1.nop<br>

                # import and keep labels (via -d flag)<br>
                zpool import -d /dev/gpt mpool<br>
            </code>
        </p>

        <!--#include virtual="/disqus.html"-->
    </div>
    <!--#include virtual="/footer.html"-->
</body>
</html>
